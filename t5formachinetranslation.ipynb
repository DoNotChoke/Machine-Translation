{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import T5Tokenizer, AutoModelForSeq2SeqLM\n\nmodel_name = \"mrm8488/t5-small-finetuned-imdb-sentiment\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:10.351114Z","iopub.execute_input":"2025-03-07T02:49:10.351453Z","iopub.status.idle":"2025-03-07T02:49:34.400267Z","shell.execute_reply.started":"2025-03-07T02:49:10.351427Z","shell.execute_reply":"2025-03-07T02:49:34.398967Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6768fa8fcc9469e991a27904dc6274f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a40d754a49124536a0a7cae59b21afc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9596e327e8534508a072d8f7ba14cead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f52f8faa0f0b475982c2b389662eef08"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99ceaa36febd4aa09c1d85ad8d31aa61"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.402482Z","iopub.execute_input":"2025-03-07T02:49:34.404198Z","iopub.status.idle":"2025-03-07T02:49:34.413150Z","shell.execute_reply.started":"2025-03-07T02:49:34.404160Z","shell.execute_reply":"2025-03-07T02:49:34.412283Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Text Classification","metadata":{}},{"cell_type":"code","source":"input = \"This book is normal.\"\nlabel = \"positive\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.415360Z","iopub.execute_input":"2025-03-07T02:49:34.415599Z","iopub.status.idle":"2025-03-07T02:49:34.551926Z","shell.execute_reply.started":"2025-03-07T02:49:34.415570Z","shell.execute_reply":"2025-03-07T02:49:34.550990Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"encoded_input = tokenizer(input, return_tensors=\"pt\")\nencoded_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.553358Z","iopub.execute_input":"2025-03-07T02:49:34.553663Z","iopub.status.idle":"2025-03-07T02:49:34.584981Z","shell.execute_reply.started":"2025-03-07T02:49:34.553639Z","shell.execute_reply":"2025-03-07T02:49:34.584056Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 100,  484,   19, 1389,    5,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"encoded_label = tokenizer(label, return_tensors=\"pt\")\nencoded_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.586031Z","iopub.execute_input":"2025-03-07T02:49:34.586563Z","iopub.status.idle":"2025-03-07T02:49:34.592143Z","shell.execute_reply.started":"2025-03-07T02:49:34.586528Z","shell.execute_reply":"2025-03-07T02:49:34.591501Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[1465,    1]]), 'attention_mask': tensor([[1, 1]])}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"logit = model(\n    input_ids=encoded_input.input_ids,\n    labels=encoded_label.input_ids\n)\nlogit.loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.593027Z","iopub.execute_input":"2025-03-07T02:49:34.593365Z","iopub.status.idle":"2025-03-07T02:49:34.763583Z","shell.execute_reply.started":"2025-03-07T02:49:34.593328Z","shell.execute_reply":"2025-03-07T02:49:34.762642Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"tensor(0.9455, grad_fn=<NllLossBackward0>)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"pred = model.generate(\n    encoded_input.input_ids,\n    attention_mask=encoded_input.attention_mask,\n    max_length=2\n)\npred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.764500Z","iopub.execute_input":"2025-03-07T02:49:34.764833Z","iopub.status.idle":"2025-03-07T02:49:34.816671Z","shell.execute_reply.started":"2025-03-07T02:49:34.764798Z","shell.execute_reply":"2025-03-07T02:49:34.815862Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor([[   0, 1389]])"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"tokenizer.decode([1389])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.818601Z","iopub.execute_input":"2025-03-07T02:49:34.818812Z","iopub.status.idle":"2025-03-07T02:49:34.824276Z","shell.execute_reply.started":"2025-03-07T02:49:34.818793Z","shell.execute_reply":"2025-03-07T02:49:34.823025Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'normal'"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Translation","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer, AutoModelForSeq2SeqLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.825579Z","iopub.execute_input":"2025-03-07T02:49:34.825930Z","iopub.status.idle":"2025-03-07T02:49:34.836834Z","shell.execute_reply.started":"2025-03-07T02:49:34.825901Z","shell.execute_reply":"2025-03-07T02:49:34.836189Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model_name = \"t5-small\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:34.837684Z","iopub.execute_input":"2025-03-07T02:49:34.837936Z","iopub.status.idle":"2025-03-07T02:49:37.266740Z","shell.execute_reply.started":"2025-03-07T02:49:34.837916Z","shell.execute_reply":"2025-03-07T02:49:37.265773Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6445fdf56ce64a7199bd10be14cbf14e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2443592844f843cbb60dce47f4775203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d226bd51c06a49e49309052d8bb9445a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56085d106a714f1e9854e82f425975e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c64ccf09e7643259d16021009815a6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2364195715c4c7782573b85ca8126b4"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"input = 'I go to school'\noutput = 'Ich besuche die Schule'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:51.893435Z","iopub.execute_input":"2025-03-07T02:49:51.893920Z","iopub.status.idle":"2025-03-07T02:49:51.899139Z","shell.execute_reply.started":"2025-03-07T02:49:51.893882Z","shell.execute_reply":"2025-03-07T02:49:51.897859Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"input = \"translate English to German: \" + input\ninput","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:52.630990Z","iopub.execute_input":"2025-03-07T02:49:52.631325Z","iopub.status.idle":"2025-03-07T02:49:52.636630Z","shell.execute_reply.started":"2025-03-07T02:49:52.631298Z","shell.execute_reply":"2025-03-07T02:49:52.635785Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'translate English to German: I go to school'"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"encoded_input = tokenizer(input, return_tensors=\"pt\")\nencoded_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:53.744824Z","iopub.execute_input":"2025-03-07T02:49:53.745129Z","iopub.status.idle":"2025-03-07T02:49:53.752050Z","shell.execute_reply.started":"2025-03-07T02:49:53.745106Z","shell.execute_reply":"2025-03-07T02:49:53.751340Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[13959,  1566,    12,  2968,    10,    27,   281,    12,   496,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"encoded_output = tokenizer(output, return_tensors=\"pt\")\nencoded_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:54.754544Z","iopub.execute_input":"2025-03-07T02:49:54.755010Z","iopub.status.idle":"2025-03-07T02:49:54.763102Z","shell.execute_reply.started":"2025-03-07T02:49:54.754978Z","shell.execute_reply":"2025-03-07T02:49:54.762252Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 1674,     3, 27024,    15,    67, 12853,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"logit = model(\n    input_ids=encoded_input.input_ids,\n    labels=encoded_output.input_ids\n)\nlogit.loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:56.228063Z","iopub.execute_input":"2025-03-07T02:49:56.228368Z","iopub.status.idle":"2025-03-07T02:49:56.303855Z","shell.execute_reply.started":"2025-03-07T02:49:56.228345Z","shell.execute_reply":"2025-03-07T02:49:56.303008Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor(0.3751, grad_fn=<NllLossBackward0>)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"pred = model.generate(\n    encoded_input.input_ids,\n    attention_mask=encoded_input.attention_mask,\n    max_length=20\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:57.929944Z","iopub.execute_input":"2025-03-07T02:49:57.930276Z","iopub.status.idle":"2025-03-07T02:49:58.070907Z","shell.execute_reply.started":"2025-03-07T02:49:57.930249Z","shell.execute_reply":"2025-03-07T02:49:58.070144Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"tokenizer.batch_decode(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:49:59.280575Z","iopub.execute_input":"2025-03-07T02:49:59.280883Z","iopub.status.idle":"2025-03-07T02:49:59.287183Z","shell.execute_reply.started":"2025-03-07T02:49:59.280858Z","shell.execute_reply":"2025-03-07T02:49:59.286209Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['<pad> Ich besuche die Schule</s>']"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## Fine-tuning mBART50 for EN-VI Machine Translation","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers sentencepiece datasets accelerate evaluate sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:50:03.800919Z","iopub.execute_input":"2025-03-07T02:50:03.801291Z","iopub.status.idle":"2025-03-07T02:50:08.933828Z","shell.execute_reply.started":"2025-03-07T02:50:03.801261Z","shell.execute_reply":"2025-03-07T02:50:08.932894Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"thainq107/iwslt2015-en-vi\")\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:50:11.301797Z","iopub.execute_input":"2025-03-07T02:50:11.302115Z","iopub.status.idle":"2025-03-07T02:50:14.528303Z","shell.execute_reply.started":"2025-03-07T02:50:11.302094Z","shell.execute_reply":"2025-03-07T02:50:14.527412Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/522 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9406ce228064c49b2c58b5134b652db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/17.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"787f030b47244e37a24d98a54d20952e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/181k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1ba860de9a4784b95d07e83b4fca23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/133317 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c98a1007ccaf41659757c11d326272d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1268 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7686087968364e76b615848fedfd60ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1268 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b178c6e183a74c79a5ca33b310def5da"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 133317\n    })\n    validation: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 1268\n    })\n    test: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 1268\n    })\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"facebook/mbart-large-50-many-to-many-mmt\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:50:17.262230Z","iopub.execute_input":"2025-03-07T02:50:17.263042Z","iopub.status.idle":"2025-03-07T02:50:21.134854Z","shell.execute_reply.started":"2025-03-07T02:50:17.262873Z","shell.execute_reply":"2025-03-07T02:50:21.134017Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b98197ed7a1489b81dd0cdb23b4f37f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12d46d62217c4c1cbc2cdb96bb65cc7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dd6ebdf300341a49e459872615d5413"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f11b85b7d88642aa8c2f03e2d906be95"}},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"## Encoding","metadata":{}},{"cell_type":"code","source":"import torch\n\nMAX_LEN = 75\n\ndef preprocess_function(examples):\n    input_ids = tokenizer(\n        examples[\"en\"], \n        padding=\"max_length\", \n        truncation=True, \n        max_length=MAX_LEN\n    )[\"input_ids\"]\n\n    labels = tokenizer(\n        examples[\"vi\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=MAX_LEN\n    )[\"input_ids\"]\n\n    labels = [[-100 if item == tokenizer.pad_token_id else item \n               for item in label] for label in labels]\n    return {\n        \"input_ids\": torch.tensor(input_ids),\n        \"labels\": torch.tensor(labels)\n    }\n\npreprocessed_ds = ds.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:50:24.282525Z","iopub.execute_input":"2025-03-07T02:50:24.282836Z","iopub.status.idle":"2025-03-07T02:51:31.490534Z","shell.execute_reply.started":"2025-03-07T02:50:24.282813Z","shell.execute_reply":"2025-03-07T02:51:31.489788Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/133317 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e0aaa7e99e49be95489f48b546f35a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1268 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c6458218c6b4b7a9f2287cd81d3ee54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1268 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b0d94dd64d34f209f812b2c796aac32"}},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:51:31.491551Z","iopub.execute_input":"2025-03-07T02:51:31.491819Z","iopub.status.idle":"2025-03-07T02:51:48.650584Z","shell.execute_reply.started":"2025-03-07T02:51:31.491798Z","shell.execute_reply":"2025-03-07T02:51:48.649579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f775196fd5e54a228c7f1a7cb28560f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41bf11a1b8bf4de8969b9bfca8b89488"}},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport evaluate\n\nmetric = evaluate.load(\"sacrebleu\")\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(\n        preds, skip_special_tokens=True, clean_up_tokenization_spaces=True\n    )\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(\n        labels, skip_special_tokens=True, clean_up_tokenization_spaces=True\n    )\n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result={\"bleu\": result[\"score\"]}\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:51:48.651903Z","iopub.execute_input":"2025-03-07T02:51:48.652197Z","iopub.status.idle":"2025-03-07T02:51:49.514567Z","shell.execute_reply.started":"2025-03-07T02:51:48.652154Z","shell.execute_reply":"2025-03-07T02:51:49.513896Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a04862488cb9498eb52dbb14ad8e5285"}},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Trainer","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = 'true'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:52:09.010571Z","iopub.execute_input":"2025-03-07T02:52:09.011338Z","iopub.status.idle":"2025-03-07T02:52:09.015092Z","shell.execute_reply.started":"2025-03-07T02:52:09.011307Z","shell.execute_reply":"2025-03-07T02:52:09.014264Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./en-vi-mbart50\",\n    logging_dir=\"logs\",\n    logging_steps=1000,\n    predict_with_generate=True, # for sequence generation task\n    eval_strategy=\"steps\",\n    eval_steps=1000,\n    save_strategy=\"steps\",\n    save_steps=1000,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    save_total_limit=1,\n    num_train_epochs=3,\n    load_best_model_at_end=True,\n    # report_to=\"wandb\"\n)\n\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer,\n    model=model\n)\n\ntrainer = Seq2SeqTrainer(\n    model,\n    training_args,\n    train_dataset=preprocessed_ds['train'],\n    eval_dataset=preprocessed_ds['validation'],\n    data_collator=data_collator,\n    processing_class=tokenizer,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_name = \"thainq107/en-vi-mbart50\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:52:38.518229Z","iopub.execute_input":"2025-03-07T02:52:38.518581Z","iopub.status.idle":"2025-03-07T02:52:56.371553Z","shell.execute_reply.started":"2025-03-07T02:52:38.518556Z","shell.execute_reply":"2025-03-07T02:52:56.370618Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/11.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46da64788bdc4b9385b7cfa806c2cd31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83dd7b82a62845849a38cb5ffbba8520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"882d398caa7c499b98f2e92c07866c75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/992 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af39571e87e4421784908527d3da42e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc49a17b4284fae90fb285f7cce19ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d06af45c617448e9d3f2c683f5c270a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/226 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5731b4befdb74db1b320155442aa5479"}},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"### Greedy Search","metadata":{}},{"cell_type":"code","source":"src_text = \"I will train machine translation by fine-tuning T5 model.\"\n\nencoded_text = tokenizer(src_text, return_tensors=\"pt\")\ngenerated_token = model.generate(**encoded_text)\n\ntokenizer.batch_decode(generated_token, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:53:05.260774Z","iopub.execute_input":"2025-03-07T02:53:05.261125Z","iopub.status.idle":"2025-03-07T02:53:09.119691Z","shell.execute_reply.started":"2025-03-07T02:53:05.261097Z","shell.execute_reply":"2025-03-07T02:53:09.118724Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['Tôi sẽ luyện tập phiên dịch máy móc bằng mô hình T5 tinh chỉnh .']"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"### Beam Search","metadata":{}},{"cell_type":"code","source":"src_text = \"In the next step, we consider the next possible tokens for each of the three branches we created in the previous step.\"\n\nencoded_text = tokenizer(src_text, return_tensors=\"pt\")\ngenerated_token = model.generate(**encoded_text, num_beams=5)\n\ntokenizer.batch_decode(generated_token, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:53:17.592547Z","iopub.execute_input":"2025-03-07T02:53:17.592863Z","iopub.status.idle":"2025-03-07T02:53:24.060190Z","shell.execute_reply.started":"2025-03-07T02:53:17.592840Z","shell.execute_reply":"2025-03-07T02:53:24.059238Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"['Bước tiếp theo , chúng tôi xem xét các token tiềm năng tiếp theo cho mỗi trong ba nhánh mà chúng tôi tạo ra ở bước trước .']"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"## Pipeline","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\ntranslator = pipeline(model=\"thainq107/en-vi-mbart50\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:54:08.890529Z","iopub.execute_input":"2025-03-07T02:54:08.890844Z","iopub.status.idle":"2025-03-07T02:54:16.102484Z","shell.execute_reply.started":"2025-03-07T02:54:08.890821Z","shell.execute_reply":"2025-03-07T02:54:16.101686Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"translated_text = translator(\"I go to school\", num_beams=1, do_sample=False)\ntranslated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:54:18.082705Z","iopub.execute_input":"2025-03-07T02:54:18.083042Z","iopub.status.idle":"2025-03-07T02:54:18.783836Z","shell.execute_reply.started":"2025-03-07T02:54:18.083015Z","shell.execute_reply":"2025-03-07T02:54:18.782939Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'Tôi đi học'}]"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"pred_sentences = translator(ds['test']['en'], batch_size=32, num_beams=5)\npred_sentences = [pred_sentence['generated_text'] for pred_sentence in pred_sentences]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T02:54:24.473379Z","iopub.execute_input":"2025-03-07T02:54:24.473686Z","iopub.status.idle":"2025-03-07T03:00:28.234048Z","shell.execute_reply.started":"2025-03-07T02:54:24.473664Z","shell.execute_reply":"2025-03-07T03:00:28.232962Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import sacrebleu\n\nbleu_score = sacrebleu.corpus_bleu(pred_sentences, [ds['test']['vi']], force=True)\nbleu_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:00:28.235429Z","iopub.execute_input":"2025-03-07T03:00:28.235755Z","iopub.status.idle":"2025-03-07T03:00:28.586106Z","shell.execute_reply.started":"2025-03-07T03:00:28.235730Z","shell.execute_reply":"2025-03-07T03:00:28.585411Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"BLEU = 34.17 66.5/42.2/28.0/18.9 (BP = 0.980 ratio = 0.980 hyp_len = 33060 ref_len = 33738)"},"metadata":{}}],"execution_count":33}]}